import streamlit as st
import torch
import torchvision.transforms as T
from PIL import Image, ImageFilter
import requests
from io import BytesIO
import time
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
from ultralytics import YOLO
import io


st.set_page_config(
    layout="wide",
    page_title="–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –º–∞—Å–∫–∏—Ä–æ–≤–∫–æ–π –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏",
    page_icon="üë§",
)
@st.cache_resource
def load_model():
    model = YOLO('/home/savely/ds_bootcamp/ds-phase-2/Computer-vision-project/model/face_detection.pt')  
    return model

model = load_model()

def process_image(image):
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç, –ø–æ–¥—Ö–æ–¥—è—â–∏–π –¥–ª—è –º–æ–¥–µ–ª–∏
    results = model(image, conf=0.4)
    annotated_frame = np.array(image.copy())

    for result in results:
        boxes = result.boxes
        for box in boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±–ª–∞—Å—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            roi = annotated_frame[y1:y2, x1:x2]
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–±–ª–∞—Å—Ç—å –≤ –æ–±—ä–µ–∫—Ç PIL Image
            roi_pil = Image.fromarray(roi)
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ä–∞–∑–º—ã—Ç–∏–µ —Å –ø–æ–º–æ—â—å—é PIL
            blurred_roi_pil = roi_pil.filter(ImageFilter.GaussianBlur(radius=15))
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–∞–∑–º—ã—Ç—É—é –æ–±–ª–∞—Å—Ç—å –æ–±—Ä–∞—Ç–Ω–æ –≤ –º–∞—Å—Å–∏–≤ NumPy
            blurred_roi = np.array(blurred_roi_pil)
            # –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –æ–±–ª–∞—Å—Ç—å –Ω–∞ —Ä–∞–∑–º—ã—Ç—É—é
            annotated_frame[y1:y2, x1:x2] = blurred_roi

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ–±—ä–µ–∫—Ç PIL Image
    processed_image = Image.fromarray(annotated_frame)
    return processed_image


st.subheader('–ú–æ–¥–µ–ª—å, –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü –Ω–∞ —Ñ–æ—Ç–æ')

st.write('**–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π, –∞ —Ç–∞–∫–∂–µ –∑–∞–≥—É—Ä–∑–∏—Ç—å —Ñ–æ—Ç–æ –ø–æ URL —Å—Å—ã–ª–∫–µ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. –ú–æ–¥–µ–ª—å YOLO12 –±—É–¥–µ—Ç –±–ª—é—Ä–∏—Ç –ª–∏—Ü–∞ –Ω–∞ —Ñ–æ—Ç–æ**')

uploaded_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", type=["jpg", "jpeg", "png", "bmp", "tiff"], accept_multiple_files=True)
image_url = st.text_input('–ò–ª–∏ –≤—Å—Ç–∞–≤—å—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ')

image = None

if uploaded_files or image_url:
    st.subheader('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏')

    if uploaded_files:
        st.write('**–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:**')
        for uploaded_file in uploaded_files:
            image = Image.open(uploaded_file)
            st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_container_width=True)
            processed_image = process_image(image)
            st.image(processed_image, caption='–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_container_width=True)

    if image_url:
        try:
            response = requests.get(image_url)
            image = Image.open(io.BytesIO(response.content))
            st.image(image, caption='–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_container_width=True)
            processed_image = process_image(image)
            st.image(processed_image, caption='–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ', use_container_width=True)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–µ: {e}")