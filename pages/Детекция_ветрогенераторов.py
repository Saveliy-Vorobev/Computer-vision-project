import streamlit as st
import torch
import torchvision.transforms as T
from PIL import Image, ImageFilter
import requests
from io import BytesIO
import time
import numpy as np
import matplotlib.pyplot as plt
import torch.nn as nn
from ultralytics import YOLO
import io
import urllib.request
import cv2

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ –Ω–∞—á–∞–ª–µ
st.set_page_config(
    layout="wide",
    page_title="–î–µ—Ç–µ–∫—Ü–∏—è –≤–µ—Ç—Ä–æ–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ (–ú–æ–¥–µ–ª—å YOLO12)",
    page_icon="üí®",
)


DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    model = YOLO('/home/savely/ds_bootcamp/ds-phase-2/Computer-vision-project/model/wind_turbines.pt')  
    return model

# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
model = load_model()

def get_prediction(img, model) -> int:
    start = time.time()
    results = model.predict(img) # –ü–æ–ª—É—á–∞–µ–º –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏
    end = time.time()
    pred_images = [result.plot() for result in results]
    return end-start, pred_images


# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
def get_prediction(img, model) -> tuple:
    start = time.time()
    
    # –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É–∂–µ PIL Image, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array
    if isinstance(img, Image.Image):
        img_np = np.array(img)
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º RGB –≤ BGR –µ—Å–ª–∏ –Ω—É–∂–Ω–æ (–¥–ª—è OpenCV)
        img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    else:
        img_np = img
    
    results = model.predict(img_np)
    end = time.time()
    
    pred_images = []
    for result in results:
        plotted_img = result.plot()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ü–≤–µ—Ç–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
        rgb_img = cv2.cvtColor(plotted_img, cv2.COLOR_BGR2RGB)
        pil_img = Image.fromarray(rgb_img)
        pred_images.append(pil_img)
    
    return end-start, pred_images

if 'predictions' not in st.session_state:
    st.session_state.predictions = []


# Streamlit-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
st.subheader('–î–µ—Ç–µ–∫—Ü–∏—è –≤–µ—Ç—Ä–æ–≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤')

st.write('**–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–¥–Ω–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π, –∞ —Ç–∞–∫–∂–µ –∑–∞–≥—É—Ä–∑–∏—Ç—å —Ñ–æ—Ç–æ –ø–æ URL —Å—Å—ã–ª–∫–µ –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. –ú–æ–¥–µ–ª—å YOLO12 –±—É–¥–µ—Ç –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–µ—Ç—Ä–µ–Ω–Ω—ã—Ö –º–µ–ª—å–Ω–∏—Ü**')


uploaded_file = st.sidebar.file_uploader(
    label='–ó–∞–≥—Ä—É–∂–∞–π—Ç–µ —Å–Ω–∏–º–æ–∫ —Å—é–¥–∞:', 
    type=['jpeg', 'png', 'jpg'], 
    accept_multiple_files=True
)

if uploaded_file is not None:
    for file in uploaded_file:
        image = Image.open(file)
        if model is not None:
            sec, results = get_prediction(image, model)
            st.write(f'''–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: __{sec:.4f} —Å–µ–∫—É–Ω–¥—ã__ 
        \n–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏:''')
            st.image(results, use_container_width=True)

link = st.sidebar.text_input(label='–í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ —Å—Å—ã–ª–∫—É –Ω–∞ —Å–Ω–∏–º–æ–∫')
if link is not '':
    image = Image.open(urllib.request.urlopen(link))
    if model is not None:
        sec, results = get_prediction(image, model)
        st.write(f'''–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: __{sec:.4f} —Å–µ–∫—É–Ω–¥—ã__ 
        \n–†–µ–∑—É–ª—å—Ç–∞—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏:''')
        st.image(results, use_container_width=True)


# Streamlit-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
# uploaded_files = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Ö —Ç–∏–ø–∞", 
#                                 type=["jpg", "png", "jpeg"], 
#                                 accept_multiple_files=True)  # –†–∞–∑—Ä–µ—à–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É

# image_url = st.text_input("–ó–∞–≥—Ä—É–∑–∏ —Ñ–æ—Ç–æ –ø–æ —Å—Å—ã–ª–∫–µ")

# if image_url:
#     response = requests.get(image_url)
#     image = Image.open(BytesIO(response.content))
    
#     # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
#     st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)

#     st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç")
#     label, elapsed = get_prediction(image, model)
#     st.write(f" **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å:** {label}")
#     st.caption(f"‚è± –í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {elapsed:.3f} —Å–µ–∫")

# if uploaded_files:  # uploaded_files - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
#     for uploaded_file in uploaded_files:  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω–æ
#         image = Image.open(uploaded_file).convert("RGB")  # –¢–µ–ø–µ—Ä—å uploaded_file - –æ–¥–∏–Ω —Ñ–∞–π–ª
#         st.image(image, caption=f"–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {uploaded_file.name}", use_container_width=True)
        
#         label, elapsed = get_prediction(image, model)
#         st.write(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å:** {label}")
#         st.caption(f"‚è± –í—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {elapsed:.3f} —Å–µ–∫")
#         st.markdown("---")  # –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏